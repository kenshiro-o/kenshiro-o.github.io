<!DOCTYPE html>
<html lang="en-GB" />
<head>
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

    <title>Recognising Traffic Signs 98% Accuracy &middot; </title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/favicon.ico" />
    <link rel="canonical" href="/posts/recognising-traffic-signs-98-pc-accuracy/" />

     <meta name="description" content="Traffic signs are an integral part of our road infrastructure. They provide critical information, sometimes compelling recommendations, for road users, which in" /> 

     
    
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="/img/post_covers/traffic_sign_stop_cover.jpeg"/>
    
 
    <meta name="twitter:title" content="Recognising Traffic Signs 98% Accuracy"/>
    <meta name="twitter:description" content="Traffic signs are an integral part of our road infrastructure. They provide critical information, sometimes compelling recommendations, for road users, which in"/>
    <meta name="twitter:url" content="/posts/recognising-traffic-signs-98-pc-accuracy/" />
    <meta name="twitter:site" content="@Ed_Forson"/>

    <meta property="og:site_name" content="" />
    <meta property="og:title" content="Recognising Traffic Signs 98% Accuracy &middot; Eddie&#39;s Blog" />
    <meta property="og:url" content="/posts/recognising-traffic-signs-98-pc-accuracy/" />
    

    <meta property="og:type" content="article" />
    <meta property="og:description" content="Traffic signs are an integral part of our road infrastructure. They provide critical information, sometimes compelling recommendations, for road users, which in" />

    <meta property="article:published_time" content="2017-08-24T07:52:19&#43;01:00" />
    <meta property="article:tag" content="AI" /><meta property="article:tag" content="computer-vision" /><meta property="article:tag" content="self-driving-cars" />

    <meta property="og:image" content="/img/post_covers/traffic_sign_stop_cover.jpeg"/>


    <meta name="generator" content="Hugo 0.47.1" />

    <!-- Stylesheets -->
    <link rel="stylesheet" type="text/css" href="/built/screen.css" /> 
    <link rel="stylesheet" type="text/css" href="/css/casper-two.css" /> 
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" />
     <link rel="stylesheet" href="/css/overrides.css" /> 

     

</head>


<body class="post-template">
  <div class="site-wrapper"> 

<header class="site-header outer">
  <div class="inner">
    <nav class="site-nav">
      <div class="site-nav-left">

        <ul class="nav" role="menu">
        
        
        
            <li class="" role="menuitem">
              <a href="/">Home</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/tags/software/">Software</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/categories/ai/">AI</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/categories/self-driving-cars/">Self-Driving Cars</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/categories/life/">Life</a>
            </li>
        
      </ul></div>

      <div class="site-nav-right">
        <div class="social-links">
                    

                    <a class="social-link social-link-tw" href="https://twitter.com/Ed_Forson" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg></a>

                    <a class="social-link" href="https://github.com/kenshiro-o" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>

                    <a class="social-link" href="https://www.linkedin.com/in/eddie-forson-16269b22" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 50 512 512"><path d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683 C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615 c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915 s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z" /></svg></a>

                    <a class="social-link" href="https://medium.com/@Ed_Forson" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 195 195"><path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z"/></svg></a>
        </div>  
            
      </div>

    </nav>  

  </div>
</header>

<main id="site-main" class="site-main outer" role="main">
  <div class="inner">
    
      <article class="post-full post"> 
    <header class="post-full-header">
        <section class="post-full-meta">
            <time class="post-full-meta-date" datetime="2017-08-24">24 August 2017</time>
                <span class="date-divider">/</span> <a href="/tags/ai/">#AI</a>&nbsp;<a href="/tags/computer-vision/">#computer-vision</a>&nbsp;
        </section>
        <h1 class="post-full-title">Recognising Traffic Signs 98% Accuracy</h1>
    </header>
    
    <figure class="post-full-image" style="background-image: url(/img/post_covers/traffic_sign_stop_cover.jpeg)">
    </figure>

    <section class="post-full-content">
        <div class="kg-card-markdown">
        

<p>Traffic signs are an integral part of our road infrastructure. They provide critical information, sometimes compelling recommendations, for road users, which in turn requires them to adjust their driving behaviour to make sure they adhere with whatever road regulation currently enforced. Without such useful signs, we would most likely be faced with more accidents, as drivers would not be given critical feedback on how fast they could safely go, or informed about road works, sharp turn, or school crossings ahead. In our modern age, around <a href="http://asirt.org/initiatives/informing-road-users/road-safety-facts/road-crash-statistics">1.3 million people</a> die on roads each year. This number would be much higher without our road signs.
Naturally, autonomous vehicles must also abide by road legislation and therefore recognize and understand traffic signs.</p>

<p>Traditionally, standard <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a> methods were employed to detect and classify traffic signs, but these required considerable and time-consuming manual work to handcraft important features in images. Instead, by applying deep learning to this problem, we create a model that reliably classifies traffic signs, learning to identify the most appropriate features for this problem by itself. In this post, I show how we can create a deep learning architecture that can identify traffic signs with close to 98% accuracy on the test set.</p>

<h2 id="project-setup">Project Setup</h2>

<p>The dataset is plit into training, test and validation sets, with the following characteristics:</p>

<p>Images are 32 (width) x 32 (height) x 3 (RGB color channels)
Training set is composed of 34799 images
Validation set is composed of 4410 images
Test set is composed of 12630 images
There are 43 classes (e.g. Speed Limit 20km/h, No entry, Bumpy road, etc.)
Moreover, we will be using Python 3.5 with Tensorflow to write our code.</p>

<h3 id="images-and-distribution">Images And Distribution</h3>

<p>You can see below a sample of the images from the dataset, with labels displayed above the row of corresponding images. Some of them are quite dark so we will look to improve contrast a bit later.</p>

<p>There is also a significant imbalance across classes in the training set, as shown in the histogram below. Some classes have less than 200 images, while others have over 2000. This means that our model could be biased towards over-represented classes, especially when it is unsure in its predictions. We will see later how we can mitigate this discrepancy using data augmentation.</p>

<h3 id="pre-processing-steps">Pre-Processing Steps</h3>

<p>We initially apply two pre-processing steps to our images:</p>

<h4 id="grayscale">Grayscale</h4>

<p>We convert our 3 channel image to a single grayscale image (we do the same thing in project 1 — Lane Line Detection — you can read my blog post about it <a href="https://medium.com/computer-car/udacity-self-driving-car-nanodegree-project-1-finding-lane-lines-9cd6a846c58c">HERE</a>).</p>

<h4 id="image-normalisation">Image Normalisation</h4>

<p>We center the distribution of the image dataset by subtracting each image by the dataset mean and divide by its standard deviation. This helps our model treating images uniformly. The resulting images look as follows:</p>

<h2 id="model-architecture">Model Architecture</h2>

<p>The architecture proposed is inspired from Yann Le Cun’s <a href="http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf">paper</a> on classification of traffic signs. We added a few tweaks and created a modular codebase which allows us to try out different filter sizes, depth, and number of convolution layers, as well as the dimensions of fully connected layers. In homage to Le Cun, and with a touch of cheekiness, we called such network <em>EdLeNet</em> :).</p>

<p>We mainly tried 5x5 and 3x3 filter (aka kernel) sizes, and start with depth of 32 for our first convolutional layer. EdLeNet’s 3x3 architecture is shown below:</p>

<p>he network is composed of 3 convolutional layers — kernel size is 3x3, with depth doubling at next layer — using <a href="https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29">ReLU</a> as the activation function, each followed by a 2x2 max pooling operation. The last 3 layers are fully connected, with the final layer producing 43 results (the total number of possible labels) computed using the <a href="https://www.quora.com/Why-is-softmax-activate-function-called-softmax">SoftMax</a> activation function. The network is trained using mini-batch stochastic gradient descent with the <a href="https://www.quora.com/Can-you-explain-basic-intuition-behind-ADAM-a-method-for-stochastic-optimization">Adam</a> optimizer. We build a highly modular coding infrastructure that enables us to dynamically create our models like in the following snippets:</p>

<pre><code>mc_3x3 = ModelConfig(EdLeNet, &quot;EdLeNet_Norm_Grayscale_3x3_Dropout_0.50&quot;, [32, 32, 1], [3, 32, 3], [120, 84], n_classes, [0.75, 0.5])
mc_5x5 = ModelConfig(EdLeNet, &quot;EdLeNet_Norm_Grayscale_5x5_Dropout_0.50&quot;, [32, 32, 1], [5, 32, 2], [120, 84], n_classes, [0.75, 0.5])

me_g_norm_drpt_0_50_3x3 = ModelExecutor(mc_3x3)
me_g_norm_drpt_0_50_5x5 = ModelExecutor(mc_5x5)
</code></pre>

<p>The <code>ModelConfig</code> contains information about the model such as:</p>

<p>The model function (e.g. <code>EdLeNet</code>)
the model name
input format (e.g. [32, 32, 1] for grayscale),
convolutional layers config [filter size, start depth, number of layers],
fully connected layers dimensions (e.g. [120, 84])
number of classes
dropout keep percentage values [p-conv, p-fc]</p>

<p>The <code>ModelExecutor</code> is reponsible for <em>training</em>, <em>evaluating</em>, <em>predicting</em>, and producing visualizations of our <em>activation</em> maps.</p>

<p>To better isolate our models and make sure they do not all exist under the same Tensorflow graph, we use the following useful construct:</p>

<pre><code>self.graph = tf.Graph()
with self.graph.as_default() as g:
    with g.name_scope( self.model_config.name ) as scope:

...

with tf.Session(graph = self.graph) as sess:
</code></pre>

<p>This way, we create separate graphs for <em>every</em> model, making sure there is no mixing of our variables, placeholders etc. It’s saved me a lot of headaches.</p>

<p>We actually started with a convolutional depth of 16, but obtained better results with 32 so settled on this value. We also compared color vs grayscale, standard and normalised images, and saw that grayscale tended to outperform color. Unfortunately, we barely scratched 93% test set accuracy on 3x3 or 5x5 models, not consistently reaching this milestone. Moreover, we observed some erratic loss behaviour on the validation set after a given number of epochs, which actually meant our model was overfitting on the training set and not generalising. You can see below some of our metric graphs for different model configurations.</p>
    
        </div>
    </section>

    <footer class="post-full-footer">
      <section class="author-card">
        <img class="author-profile-image" src="/img/eddie_india_small.jpeg" alt="Author" />
        <section class="author-card-content">
            <h4 class="author-card-name"><a href="/">Eddie Forson</a></h4>
                <p>UK-based, French software engineer with experience in product management. Curious. Very much into AI and self-driving cars these days.</p>
        </section>
      </section>
    </footer>
</article>
    
    
    

  </div>
</main>


<aside class="read-next outer">
  <div class="inner">
    <div class="read-next-feed">      
      

      
      <article class="post-card post"> 
    
    <a class="post-card-image-link" href="/posts/using-computer-vision-to-find-lane-lines-on-road/">
      <div class="post-card-image" style="background-image: url(/img/post_covers/basic_lane_line_detection.png)"></div>
    </a>
    

    <div class="post-card-content">
      <a class="post-card-content-link" href="/posts/using-computer-vision-to-find-lane-lines-on-road/">
          <header class="post-card-header">
              <span class="post-card-tags">
              #AI 
              #computer-vision 
              #self-driving-cars  </span>
              
              <h2 class="post-card-title">Using Computer Vision to Find Lane Lines on Road</h2>
          </header>
          <section class="post-card-excerpt">
              
                <p>Identifying lanes on the road is a common task performed by all human drivers to ensure their vehicles are within lane constraints when driving, so as to make sure traffic is smooth and minimize chances of collisions with other cars due to lane misalignment.
Similarly, it is a critical task for an autonomous vehicle to perform. It turns out that recognizing lane markings on roads is possible using well known computer vision techniques. ...  </p>
              
          </section>
      </a>

      <footer class="post-card-meta">
          <img class="author-profile-image" src="/img/eddie_india_small.jpeg" alt="Author" />
          <span class="post-card-author"><a href="/">Eddie Forson</a></span>
      </footer>
    </div>
</article>
      
      
      <article class="post-card post"> 
    
    <a class="post-card-image-link" href="/posts/3-ways-to-spend-money-to-improve-quality-of-life/">
      <div class="post-card-image" style="background-image: url(/img/post_covers/money_euros_pyramid.jpeg)"></div>
    </a>
    

    <div class="post-card-content">
      <a class="post-card-content-link" href="/posts/3-ways-to-spend-money-to-improve-quality-of-life/">
          <header class="post-card-header">
              <span class="post-card-tags">
              #life 
              #self-improvement 
              #money 
              #life-hacking  </span>
              
              <h2 class="post-card-title">3 Ways I Spend Money to Improve Quality of Life</h2>
          </header>
          <section class="post-card-excerpt">
              
                <p>The illiterate of the future will not be the person who does not read. It will be the person who does not know how to learn - Alvin Toffler
I practice andragogy, which means I am constantly investing in my education as an adult, for betterment, fun, and naturally profit! This takes many forms, but one of the media I consume most is podcasts, and one of the podcasts I intently listen to is The Tim Ferriss Show. ...  </p>
              
          </section>
      </a>

      <footer class="post-card-meta">
          <img class="author-profile-image" src="/img/eddie_india_small.jpeg" alt="Author" />
          <span class="post-card-author"><a href="/">Eddie Forson</a></span>
      </footer>
    </div>
</article>
      
    </div>
  </div>
</aside>

<div class="floating-header">
  <div class="floating-header-logo">
    <a href="/">
      
      <span></span>
    </a>
  </div>
  <span class="floating-header-divider">&mdash;</span>
  <div class="floating-header-title">Recognising Traffic Signs 98% Accuracy</div>
  <div class="floating-header-share">
    <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
     <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/></svg>
    </div>
    
    <a class="floating-header-share-tw" href="https://twitter.com/share?text=Recognising%20Traffic%20Signs%2098%25%20Accuracy&amp;url=%2fposts%2frecognising-traffic-signs-98-pc-accuracy%2f"
          onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
      </a>
      <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=%2fposts%2frecognising-traffic-signs-98-pc-accuracy%2f"
          onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
      </a>
  </div>

  <progress class="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</div>



<footer class="site-footer outer">
  <div class="site-footer-content inner">
    <section class="copyright" style="line-height: 1.3em;">
      <a href="/">EF</a>  <br>
      
    </section>
    <nav class="site-footer-nav">
        <a href="/">Latest Posts</a>
        
        <a href="https://twitter.com/Ed_Forson" target="_blank" rel="noopener">Twitter</a>
        <a href="https://github.com/kenshiro-o" target="_blank" rel="noopener">Github</a>
        <a href="https://www.linkedin.com/in/eddie-forson-16269b22" target="_blank" rel="noopener">LinkedIn</a>
        <a href="https://medium.com/@Ed_Forson" target="_blank" rel="noopener">Medium</a>
    </nav>  
  </div>
</footer>

</div>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script type="text/javascript" src="//code.jquery.com/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="/js/jquery.fitvids.js"></script>

<script>hljs.initHighlightingOnLoad();</script>



    <script>





$(document).ready(function () {
    
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>
</body></html>
